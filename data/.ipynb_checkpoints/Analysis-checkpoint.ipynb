{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import itertools\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta statistics\n",
    "sl_set = []\n",
    "OOV_count_set = []\n",
    "vocab_count_set = []\n",
    "sl_stats_set = []\n",
    "\n",
    "datasets = [\"unaligned.en\", \"unaligned.fr\", \"train.en\", \"train.fr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.perf_counter()\n",
    "for path in datasets:\n",
    "    bow = []\n",
    "    sentence_length = []\n",
    "    vocab_alpha = {}\n",
    "    OOV = {}\n",
    "    real_vocab = {}\n",
    "    with open(\"processed/\" + path, \"r\") as text_file:\n",
    "        for line in text_file:\n",
    "            stripped_line = line.strip()\n",
    "            bow.extend(stripped_line.split())\n",
    "            sentence_length.append(len(stripped_line.split()))\n",
    "    # Word Count + Dictionary    \n",
    "#     print(\"Word Count Total: \", sum(sentence_length))\n",
    "    vocab = pd.DataFrame(list(zip(bow, bow, [1] * len(bow))), columns =['Word', 'Token','Count']).groupby('Word',sort=False)['Token'].count().to_dict()\n",
    "#     for word, count in vocab.items():\n",
    "        if any(c.isalpha() for c in word):\n",
    "            vocab_alpha[word] = count\n",
    "        else:\n",
    "            OOV[word] = count\n",
    "    real_vocab = vocab_alpha.copy()\n",
    "#     real_vocab['num'] = sum(OOV.values()) # Could be removed\n",
    "    real_vocab = {k: v / total for total in (sum(real_vocab.values(), 0.0),) for k, v in real_vocab.items()}\n",
    "    real_vocab = {k: v for k, v in sorted(real_vocab.items(), key=lambda item: item[1], reverse=True)}\n",
    "    with open( path +'.json', 'w') as fp:\n",
    "        json.dump(real_vocab, fp)\n",
    "#     print(\"Total Vocab Size by Words: \", len(vocab))\n",
    "#     print(\"OOV Size: \", len(OOV))\n",
    "#     print(\"Net Vocab Size: \", len(vocab_alpha))\n",
    "\n",
    "    # Word Frequency\n",
    "    wf = np.asarray(list(vocab_alpha.values()))\n",
    "    wf_metrics = {\"min\": np.amin(wf), \"max\": np.amax(wf), \"mean\": np.mean(wf), \"std\": np.std(wf)}\n",
    "#     print(\"Word Frequency Info: \", wf_metrics)\n",
    "\n",
    "    # Most Frequent Words\n",
    "    sorted_vocab = dict(sorted(vocab_alpha.items(), key=operator.itemgetter(1),reverse=True))\n",
    "    top = dict(itertools.islice(sorted_vocab.items(), 20))\n",
    "#     print(\"Most Common Words: \", top)\n",
    "\n",
    "    # Sentence Lengths\n",
    "    sl = np.asarray(sentence_length)\n",
    "    sentence_len_metrics = {\"min\": np.amin(sl), \"max\": np.amax(sl), \"mean\": np.mean(sl), \"std\": np.std(sl)}\n",
    "#     print(\"Sentence Length Info: \",sentence_len_metrics)\n",
    "\n",
    "    # Append to metadata\n",
    "    sl_set.append(sl)\n",
    "    OOV_count_set.append(len(OOV))\n",
    "    vocab_count_set.append(len(vocab_alpha))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('unaligned.en.json') as f:\n",
    "    uni_en = json.load(f)\n",
    "with open('unaligned.fr.json') as f:\n",
    "    uni_fr = json.load(f)\n",
    "with open('train.en.json') as f:\n",
    "    train_en = json.load(f)\n",
    "with open('train.fr.json') as f:\n",
    "    train_fr = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_pd = pd.DataFrame.from_dict(train_en, orient='index', columns=['parallel']).reset_index().rename(columns={\"index\": \"word\"})\n",
    "train_fr_pd = pd.DataFrame.from_dict(train_fr, orient='index', columns=['parallel']).reset_index().rename(columns={\"index\": \"word\"})\n",
    "uni_en_pd = pd.DataFrame.from_dict(uni_en, orient='index', columns=['mono']).reset_index().rename(columns={\"index\": \"word\"})\n",
    "uni_fr_pd = pd.DataFrame.from_dict(uni_fr, orient='index', columns=['mono']).reset_index().rename(columns={\"index\": \"word\"})\n",
    "english = train_en_pd.merge(uni_en_pd, on='word', how='left').set_index('word')\n",
    "french = train_fr_pd.merge(uni_fr_pd, on='word', how='left').set_index('word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_8dba1712_789d_11ea_a507_631e9e5a04b3row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_8dba1712_789d_11ea_a507_631e9e5a04b3row0_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_8dba1712_789d_11ea_a507_631e9e5a04b3row1_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_8dba1712_789d_11ea_a507_631e9e5a04b3row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_8dba1712_789d_11ea_a507_631e9e5a04b3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >parallel</th>        <th class=\"col_heading level0 col1\" >mono</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_8dba1712_789d_11ea_a507_631e9e5a04b3level0_row0\" class=\"row_heading level0 row0\" >parallel</th>\n",
       "                        <td id=\"T_8dba1712_789d_11ea_a507_631e9e5a04b3row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_8dba1712_789d_11ea_a507_631e9e5a04b3row0_col1\" class=\"data row0 col1\" >0.999736</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_8dba1712_789d_11ea_a507_631e9e5a04b3level0_row1\" class=\"row_heading level0 row1\" >mono</th>\n",
       "                        <td id=\"T_8dba1712_789d_11ea_a507_631e9e5a04b3row1_col0\" class=\"data row1 col0\" >0.999736</td>\n",
       "                        <td id=\"T_8dba1712_789d_11ea_a507_631e9e5a04b3row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6dce3b6e10>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "corr_en = english.corr()\n",
    "corr_en.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_96b92cea_789d_11ea_a507_631e9e5a04b3row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_96b92cea_789d_11ea_a507_631e9e5a04b3row0_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_96b92cea_789d_11ea_a507_631e9e5a04b3row1_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_96b92cea_789d_11ea_a507_631e9e5a04b3row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "            color:  #f1f1f1;\n",
       "        }</style><table id=\"T_96b92cea_789d_11ea_a507_631e9e5a04b3\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >parallel</th>        <th class=\"col_heading level0 col1\" >mono</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_96b92cea_789d_11ea_a507_631e9e5a04b3level0_row0\" class=\"row_heading level0 row0\" >parallel</th>\n",
       "                        <td id=\"T_96b92cea_789d_11ea_a507_631e9e5a04b3row0_col0\" class=\"data row0 col0\" >1</td>\n",
       "                        <td id=\"T_96b92cea_789d_11ea_a507_631e9e5a04b3row0_col1\" class=\"data row0 col1\" >0.995266</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_96b92cea_789d_11ea_a507_631e9e5a04b3level0_row1\" class=\"row_heading level0 row1\" >mono</th>\n",
       "                        <td id=\"T_96b92cea_789d_11ea_a507_631e9e5a04b3row1_col0\" class=\"data row1 col0\" >0.995266</td>\n",
       "                        <td id=\"T_96b92cea_789d_11ea_a507_631e9e5a04b3row1_col1\" class=\"data row1 col1\" >1</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6dc5f53a10>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr_fr = french.corr()\n",
    "corr_fr.style.background_gradient(cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[10,8])\n",
    "# plt.hist(sl, bins=50)\n",
    "# plt.title(\"Monolingual English, Sentence Length Distribution\")\n",
    "# plt.ylabel('Number of Sentences',fontsize=10)\n",
    "# plt.xlabel('Sentence Length',fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[20,12])\n",
    "# plt.bar(top.keys(), top.values())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[10,8])\n",
    "# plt.hist(sl, bins=50)\n",
    "# plt.title(\"Monolingual French, Sentence Length Distribution\")\n",
    "# plt.ylabel('Number of Sentences',fontsize=10)\n",
    "# plt.xlabel('Sentence Length',fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[20,12])\n",
    "# plt.bar(top.keys(), top.values())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[10,8])\n",
    "# plt.hist(sl, bins=50)\n",
    "# plt.title(\"Parallel English, Sentence Length Distribution\")\n",
    "# plt.ylabel('Number of Sentences',fontsize=10)\n",
    "# plt.xlabel('Sentence Length',fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[20,12])\n",
    "# plt.bar(top.keys(), top.values())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[10,8])\n",
    "# plt.hist(sl, bins=50)\n",
    "# plt.title(\"Parallel French, Sentence Length Distribution\")\n",
    "# plt.ylabel('Number of Sentences',fontsize=10)\n",
    "# plt.xlabel('Sentence Length',fontsize=10)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=[20,12])\n",
    "# plt.bar(top.keys(), top.values())\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sentence Lengths\n",
    "# plt.figure(figsize=[10,8])\n",
    "# sns.boxplot(data = sl_set)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # OOVs in relation to real vocab\n",
    "# groups = ['Unaligned FR', 'Unalgined EN', 'Parallel FR', 'Parallel EN']\n",
    "# oovs = np.asarray(OOV_count_set)\n",
    "# reals = np.asarray(vocab_count_set)\n",
    "# ind = [x for x, _ in enumerate(groups)]\n",
    "\n",
    "# plt.bar(ind, oovs, width=0.8, label='silvers', color='grey', bottom=reals)\n",
    "# plt.bar(ind, reals, width=0.8, label='bronzes', color='blue')\n",
    "\n",
    "# plt.xticks(ind, groups)\n",
    "# plt.ylabel(\"Vocab Size\")\n",
    "# plt.xlabel(\"Groups\")\n",
    "# plt.legend(loc=\"upper right\")\n",
    "# plt.title(\"OOVs vs Vocab\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
